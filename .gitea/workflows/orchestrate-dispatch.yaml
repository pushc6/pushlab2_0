name: orchestrate-dispatch

on:
  workflow_dispatch:
    inputs:
      environment:
        description: "Target environment (lab|prod)"
        required: true
        default: "lab"
      action:
        description: "terraform action (plan|apply)"
        required: true
        default: "plan"
      build_packer:
        description: "Build Packer template first (true|false)"
        required: true
        default: "false"
      packer_force:
        description: "Force rebuild existing template (true|false)"
        required: false
        default: "false"

jobs:
  validate:
    runs-on: [self-hosted, linux, x64, alma]
    container: almalinux:10
    steps:
      - name: Prep tools (dnf)
        run: |
          dnf -y makecache
          # Ensure Node.js is present for JavaScript-based actions (actions/checkout)
          dnf -y module enable nodejs:20 || true
          dnf -y install unzip curl jq git openssh-clients ca-certificates tar which nodejs

      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Terraform
        run: |
          curl -fsSL https://releases.hashicorp.com/terraform/1.7.5/terraform_1.7.5_linux_amd64.zip -o /tmp/terraform.zip
          unzip -o /tmp/terraform.zip -d /usr/local/bin
          terraform -version

      - name: Terraform fmt/validate (lab)
        run: |
          terraform -chdir=terraform/envs/lab init -backend=false
          terraform -chdir=terraform/envs/lab fmt -check
          terraform -chdir=terraform/envs/lab validate

      - name: Terraform fmt/validate (prod)
        run: |
          terraform -chdir=terraform/envs/prod init -backend=false
          terraform -chdir=terraform/envs/prod fmt -check
          terraform -chdir=terraform/envs/prod validate

  packer-build:
    runs-on: [self-hosted, linux, x64, alma]
    container: almalinux:10
    needs: [validate]
    steps:
      - name: Prep tools (dnf)
        run: |
          dnf -y makecache
          # Ensure Node.js is present for JavaScript-based actions (actions/checkout)
          dnf -y module enable nodejs:20 || true
          dnf -y install unzip curl jq git openssh-clients ca-certificates tar which nodejs

      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Packer
        run: |
          curl -fsSL https://releases.hashicorp.com/packer/1.11.2/packer_1.11.2_linux_amd64.zip -o /tmp/packer.zip
          unzip -o /tmp/packer.zip -d /usr/local/bin

      - name: Respect build_packer input
        id: gate
        run: |
          set -euo pipefail
          VAL=$(jq -r '.inputs.build_packer // "false"' "$GITHUB_EVENT_PATH" 2>/dev/null || echo false)
          if [ "$VAL" = "true" ]; then
            echo "should_build=true" >> "$GITHUB_OUTPUT"
          else
            echo "should_build=false" >> "$GITHUB_OUTPUT"
            echo "Skipping Packer build (build_packer != true)"
          fi

      - name: Generate ephemeral SSH key for template communicator
        if: ${{ steps.gate.outputs.should_build == 'true' }}
        run: |
          ssh-keygen -t ed25519 -N "" -C "ci@orchestrate" -f /tmp/ci_key
          echo "SSH_PUBLIC_KEY=$(cat /tmp/ci_key.pub)" >> $GITHUB_ENV

      - name: Packer build template
        if: ${{ steps.gate.outputs.should_build == 'true' }}
        env:
          VCENTER_SERVER: ${{ secrets.VCENTER_SERVER || vars.VCENTER_SERVER || vars.vcenter_server || secrets.VSPHERE_SERVER || vars.VSPHERE_SERVER || vars.vsphere_server }}
          VSPHERE_USER: ${{ secrets.VSPHERE_USER }}
          VSPHERE_PASSWORD: ${{ secrets.VSPHERE_PASSWORD }}
          SSH_PUBLIC_KEY: ${{ env.SSH_PUBLIC_KEY }}
        run: |
          if [ -z "${VCENTER_SERVER:-}" ] || [ -z "${VSPHERE_USER:-}" ] || [ -z "${VSPHERE_PASSWORD:-}" ]; then
            echo "Missing required Packer inputs: VCENTER_SERVER, VSPHERE_USER, or VSPHERE_PASSWORD not set (check Gitea secrets/variables)." >&2
            exit 1
          fi
          # Normalize vcenter_server: strip any scheme (http://, https://, or typos like http//) and any path (/sdk)
          RAW_VC="$VCENTER_SERVER"
          NORM_VC="${RAW_VC#http://}"; NORM_VC="${NORM_VC#https://}"
          NORM_VC="${NORM_VC#http//}";  NORM_VC="${NORM_VC#https//}"
          NORM_VC="${NORM_VC%%/*}"
          if [ -z "$NORM_VC" ] || [ "$NORM_VC" = "http" ] || [ "$NORM_VC" = "https" ]; then
            echo "VCENTER_SERVER value '$RAW_VC' is invalid after normalization; please set to just host or IP (e.g., 10.37.10.35)." >&2
            exit 1
          fi
          echo "Using vCenter host: $NORM_VC"
          FORCE=$(jq -r '.inputs.packer_force // "false"' "$GITHUB_EVENT_PATH" 2>/dev/null || echo false)
          EXTRA=""
          if [ "$FORCE" = "true" ]; then EXTRA="-force"; fi
          packer init packer
          packer build $EXTRA \
            -var "vcenter_server=${NORM_VC}" \
            -var "vcenter_username=${VSPHERE_USER}" \
            -var "vcenter_password=${VSPHERE_PASSWORD}" \
            -var "ssh_public_key=${SSH_PUBLIC_KEY}" \
            -var "ssh_private_key_file=/tmp/ci_key" \
            packer/alma-template.pkr.hcl

  terraform:
    runs-on: [self-hosted, linux, x64, alma]
    container: almalinux:10
    needs: [validate, packer-build]
    steps:
      - name: Prep tools (dnf)
        run: |
          dnf -y makecache
          # Ensure Node.js is present for JavaScript-based actions (actions/checkout)
          dnf -y module enable nodejs:20 || true
          dnf -y install unzip curl jq git openssh-clients ca-certificates tar which nodejs

      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Terraform
        run: |
          curl -fsSL https://releases.hashicorp.com/terraform/1.7.5/terraform_1.7.5_linux_amd64.zip -o /tmp/terraform.zip
          unzip -o /tmp/terraform.zip -d /usr/local/bin

      - name: Select environment from inputs
        id: envsel
        run: |
          set -euo pipefail
          ENVIRONMENT=$(jq -r '.inputs.environment // "lab"' "$GITHUB_EVENT_PATH" 2>/dev/null || echo lab)
          if [ "$ENVIRONMENT" = "prod" ]; then
            echo "TF_DIR=terraform/envs/prod" >> "$GITHUB_OUTPUT"
            echo "TF_VARS=prod.tfvars" >> "$GITHUB_OUTPUT"
          else
            echo "TF_DIR=terraform/envs/lab" >> "$GITHUB_OUTPUT"
            echo "TF_VARS=lab.tfvars" >> "$GITHUB_OUTPUT"
          fi

      - name: Terraform init with S3-compatible backend
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}
          AWS_REGION: us-east-005
          AWS_EC2_METADATA_DISABLED: "true"
        run: |
          set -euo pipefail
          TF_DIR="${{ steps.envsel.outputs.TF_DIR }}"
          if [ -f "$TF_DIR/backend.s3.secrets.hcl" ]; then
            echo "Found local backend.s3.secrets.hcl; using it for init"
            terraform -chdir="$TF_DIR" init \
              -backend-config=backend.hcl \
              -backend-config=backend.s3.secrets.hcl \
              -reconfigure \
              -input=false
          else
            echo "No local backend.s3.secrets.hcl; using CI-provided AWS_* secrets"
            terraform -chdir="$TF_DIR" init \
              -backend-config=backend.hcl \
              -reconfigure \
              -input=false
          fi

      - name: Terraform plan/apply based on input
        env:
          TF_VAR_vsphere_user: ${{ secrets.VSPHERE_USER }}
          TF_VAR_vsphere_password: ${{ secrets.VSPHERE_PASSWORD }}
          TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}
          AWS_REGION: us-east-005
          AWS_EC2_METADATA_DISABLED: "true"
        run: |
          set -euo pipefail
          ACTION=$(jq -r '.inputs.action // "plan"' "$GITHUB_EVENT_PATH" 2>/dev/null || echo plan)
          TF_DIR="${{ steps.envsel.outputs.TF_DIR }}"
          TF_VARS_FILE="${{ steps.envsel.outputs.TF_VARS }}"
          # Always produce a fresh plan with the selected var-file for safety
          terraform -chdir="$TF_DIR" plan -var-file="$TF_VARS_FILE" -out=tfplan.out
          if [ "$ACTION" = "apply" ]; then
            terraform -chdir="$TF_DIR" apply -auto-approve tfplan.out
          else
            echo "ACTION=$ACTION; plan only"
          fi

      - name: Snapshot IaC after prod apply
        if: ${{ github.event.inputs.environment == 'prod' && github.event.inputs.action == 'apply' }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}
          AWS_REGION: us-east-005
          AWS_EC2_METADATA_DISABLED: "true"
          TF_SNAPSHOT_BUCKET: ${{ secrets.TF_SNAPSHOT_BUCKET || vars.TF_SNAPSHOT_BUCKET }}
          AWS_S3_ENDPOINT: ${{ secrets.AWS_S3_ENDPOINT }}
        run: |
          set -euo pipefail
          dnf -y install awscli jq tar >/dev/null 2>&1 || true
          TF_DIR=terraform/envs/prod
          SHORT=$(echo "${GITHUB_SHA:-$GITEA_SHA}" | cut -c1-7)
          VERSION="iac-prod-$(date -u +%Y%m%d-%H%M)-$SHORT"
          SNAPDIR="/tmp/iac-snap/$VERSION"
          mkdir -p "$SNAPDIR"
          terraform -chdir="$TF_DIR" state pull > "$SNAPDIR/terraform.tfstate"
          cp "$TF_DIR/prod.tfvars" "$SNAPDIR/" 2>/dev/null || true
          terraform -chdir="$TF_DIR" output -json > "$SNAPDIR/outputs.json" || true
          jq -n --arg ver "$VERSION" --arg sha "${GITHUB_SHA:-$GITEA_SHA}" \
               --arg repo "${GITHUB_REPOSITORY:-$GITEA_REPOSITORY}" \
               --arg when "$(date -u +%FT%TZ)" '{version:$ver,sha:$sha,repo:$repo,when:$when,env:"prod"}' \
               > "$SNAPDIR/manifest.json"
          tar -C /tmp/iac-snap -czf "/tmp/${VERSION}.tgz" "$VERSION"
          echo "SNAP_VERSION=$VERSION" >> $GITHUB_ENV

      - name: Upload IaC snapshot artifact
        if: ${{ github.event.inputs.environment == 'prod' && github.event.inputs.action == 'apply' }}
        uses: actions/upload-artifact@v3
        with:
          name: iac-snapshot-prod
          path: /tmp/iac-prod-*.tgz
          retention-days: 30

      - name: Copy IaC snapshot to S3 (optional)
        if: ${{ github.event.inputs.environment == 'prod' && github.event.inputs.action == 'apply' && (secrets.TF_SNAPSHOT_BUCKET != '' || vars.TF_SNAPSHOT_BUCKET != '') }}
        env:
          # Prefer dedicated Backblaze/Snapshot credentials, fallback to generic AWS_*
          AWS_ACCESS_KEY_ID: ${{ secrets.SNAPSHOT_S3_ACCESS_KEY_ID || secrets.B2_KEY_ID || secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SNAPSHOT_S3_SECRET_ACCESS_KEY || secrets.B2_APPLICATION_KEY || secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_SESSION_TOKEN: ${{ secrets.SNAPSHOT_S3_SESSION_TOKEN || secrets.AWS_SESSION_TOKEN }}
          AWS_REGION: ${{ secrets.SNAPSHOT_S3_REGION || vars.SNAPSHOT_S3_REGION || 'us-east-005' }}
          AWS_EC2_METADATA_DISABLED: "true"
          TF_SNAPSHOT_BUCKET: ${{ secrets.TF_SNAPSHOT_BUCKET || vars.TF_SNAPSHOT_BUCKET }}
          AWS_S3_ENDPOINT: ${{ secrets.SNAPSHOT_S3_ENDPOINT || secrets.AWS_S3_ENDPOINT }}
        run: |
          set -euo pipefail
          FILE="/tmp/${SNAP_VERSION}.tgz"
          DEST="s3://${TF_SNAPSHOT_BUCKET}/iac-snapshots/prod/${SNAP_VERSION}/"
          # If no explicit endpoint is provided but the region looks like Backblaze (e.g., us-east-005),
          # default to the Backblaze B2 S3-compatible endpoint.
          if [ -z "${AWS_S3_ENDPOINT:-}" ]; then
            case "${AWS_REGION:-}" in
              us-east-005|us-west-002|eu-central-003|ap-southeast-001)
                AWS_S3_ENDPOINT="https://s3.${AWS_REGION}.backblazeb2.com"
                echo "Using Backblaze S3-compatible endpoint: $AWS_S3_ENDPOINT"
                ;;
            esac
          fi

          ARGS=();
          if [ -n "${AWS_S3_ENDPOINT:-}" ]; then
            ARGS+=(--endpoint-url "$AWS_S3_ENDPOINT")
            aws configure set default.s3.addressing_style path || true
          fi
          aws "${ARGS[@]}" s3 cp "$FILE" "$DEST"

      - name: Create Gitea Release (API, optional)
        if: ${{ github.event.inputs.environment == 'prod' && github.event.inputs.action == 'apply' && (secrets.GIT_TOKEN != '' || secrets.GITEA_TOKEN != '') && (vars.GIT_SERVER_URL != '' || secrets.GIT_SERVER_URL != '') }}
        env:
          GIT_TOKEN: ${{ secrets.GIT_TOKEN || secrets.GITEA_TOKEN }}
          # GIT_SERVER_URL should be a repository variable (non-secret); fallback to secret of same name only
          GIT_SERVER_URL: ${{ vars.GIT_SERVER_URL || secrets.GIT_SERVER_URL }}
        run: |
          set -euo pipefail
          if [ -z "${GIT_SERVER_URL:-}" ]; then echo "No GIT_SERVER_URL; skipping release"; exit 0; fi
          OWNER=$(echo "${GITHUB_REPOSITORY:-$GITEA_REPOSITORY}" | cut -d/ -f1)
          REPO=$(echo "${GITHUB_REPOSITORY:-$GITEA_REPOSITORY}" | cut -d/ -f2)
          TAG="$SNAP_VERSION"
          NAME="IaC snapshot: $SNAP_VERSION"
          BODY="Automated IaC snapshot for prod apply at ${SNAP_VERSION}."
          # Build JSON body with jq to avoid heredoc YAML parsing issues
          jq -n --arg tag "$TAG" --arg target "${GITHUB_SHA:-$GITEA_SHA}" --arg name "$NAME" --arg body "$BODY" \
            '{tag_name:$tag, target_commitish:$target, name:$name, body:$body}' > /tmp/release_body.json
          HTTP=$(curl -sS -o /tmp/release.json -w "%{http_code}" -X POST "${GIT_SERVER_URL}/api/v1/repos/${OWNER}/${REPO}/releases" \
            -H "Authorization: token ${GIT_TOKEN}" -H 'Content-Type: application/json' \
            -d @/tmp/release_body.json)
          echo "Create release HTTP=$HTTP"; cat /tmp/release.json || true
          REL_ID=$(jq -r '.id // empty' /tmp/release.json || true)
          if [ -n "$REL_ID" ]; then
            FILE="/tmp/${SNAP_VERSION}.tgz"; NAME_FILE="${SNAP_VERSION}.tgz"
            UP_HTTP=$(curl -sS -o /tmp/asset.json -w "%{http_code}" -X POST "${GIT_SERVER_URL}/api/v1/repos/${OWNER}/${REPO}/releases/${REL_ID}/assets?name=${NAME_FILE}" \
              -H "Authorization: token ${GIT_TOKEN}" \
              -F "attachment=@${FILE}")
            echo "Upload asset HTTP=$UP_HTTP"; cat /tmp/asset.json || true
          fi

      - name: Fallback tag push (optional)
        if: ${{ github.event.inputs.environment == 'prod' && github.event.inputs.action == 'apply' && secrets.GIT_TOKEN == '' && secrets.GITEA_TOKEN == '' }}
        run: |
          set -euo pipefail
          # Best-effort: create an annotated tag locally; push may depend on runner credentials
          git config user.name "ci"
          git config user.email "ci@local"
          git tag -a "$SNAP_VERSION" -m "IaC snapshot prod apply $SNAP_VERSION" || true
          git push origin "$SNAP_VERSION" || true

  ansible-aap:
    runs-on: [self-hosted, linux, x64, alma]
    container: almalinux:10
    needs: [terraform]
    steps:
      - name: Prep tools (dnf)
        run: |
          dnf -y makecache
          dnf -y install curl jq ca-certificates
      - name: Trigger AAP Job Template (apply only)
        env:
          AAP_URL: ${{ secrets.AAP_URL }}
          AAP_TOKEN: ${{ secrets.AAP_TOKEN }}
          AAP_JOB_TEMPLATE_ID: ${{ secrets.AAP_JOB_TEMPLATE_ID }}
        run: |
          set -euo pipefail
          ACTION=$(jq -r '.inputs.action // "plan"' "$GITHUB_EVENT_PATH" 2>/dev/null || echo plan)
          TARGET_ENV=$(jq -r '.inputs.environment // "lab"' "$GITHUB_EVENT_PATH" 2>/dev/null || echo lab)
          if [ "$ACTION" != "apply" ]; then
            echo "ACTION=$ACTION; skipping AAP trigger (apply only)"
            exit 0
          fi
          if [ -z "$AAP_URL" ] || [ -z "$AAP_TOKEN" ] || [ -z "$AAP_JOB_TEMPLATE_ID" ]; then echo "AAP secrets not set; skipping"; exit 0; fi
          curl -s -X POST "$AAP_URL/api/v2/job_templates/${AAP_JOB_TEMPLATE_ID}/launch/" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer $AAP_TOKEN" \
            -d '{"extra_vars": {"target_env": "'"$TARGET_ENV"'"}}' | jq .
